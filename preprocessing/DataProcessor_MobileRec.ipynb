{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Construction - MobileRec\n",
    "\n",
    "This notebook aims to model any recommender system datasets to the unified sequential format of pure text string, serving as the input of the user simulator LLM.\n",
    "\n",
    "A recommender system data usually consists of 3 critical components: user, item and behavior. The user and item are usually represented by their IDs, while the behavior is usually represented by their interactions.\n",
    "\n",
    "The goal of this notebook is to transform the original data into a unified format, with two types of JSON format:\n",
    "\n",
    "- Item Feature JSON: This JSON contains a list of all items in the dataset, each element is following the format:\n",
    "```json\n",
    "{\n",
    "    \"item_id\": \"item_id (str), a unique identifier for the item\",\n",
    "    \"item_description\": \"item_description (dict[str, str]), a dictionary of item attributes and their values. All values should be processed to be pure text string that can be understood by human. All features that contain unreadable information (e.g. image, video, audio, url, ID string ,etc.) should be converted (when possible) or removed (when not possible) to be pure text string.\",\n",
    "    \"item_features\": \"item_features (dict[str, Any]), a dictionary of item features (except for those in item_description) and their values. \"\n",
    "This JSON is stored as `<DATASET_NAME>_item_feature.jsonl`.\n",
    "\n",
    "- User Feature JSON: This JSON contains a list of all items in the dataset, each element is following the format:\n",
    "```json\n",
    "{\n",
    "    \"user_id\": \"user_id (str), a unique identifier for the user\",\n",
    "    \"user_description\": \"user_description (dict[str, str]), a dictionary of user attributes and their values. All values should be processed to be pure text string that can be understood by human. All features that contain unreadable information (e.g. image, video, audio, url, ID string ,etc.) should be converted (when possible) or removed (when not possible) to be pure text string.\",\n",
    "    \"user_features\": \"user_features (dict[str, Any]), a dictionary of user features (except for those in user_description) and their values. \"\n",
    "}\n",
    "```\n",
    "This JSON is stored as `<DATASET_NAME>_user_feature.jsonl`.\n",
    "\n",
    "- Interaction JSON: This JSON contains a list of all user behaviors in the dataset, each element is following the format:\n",
    "```json\n",
    "{\n",
    "    \"user_id\": \"user_id (str), a unique identifier for the user\",\n",
    "    \"item_id\": \"item_id (str), the ID of the item that the user has interacted with\",\n",
    "    \"timestamp\": \"timestamp (str), the timestamp of the interaction in the format of YYYY-MM-DD HH:MM:SS. When the timestamp is not available, it should be set to the random timestamp.\",\n",
    "    \"behavior_features\": \"behavior_features (dict[str, Any]), a dictionary of behavior features and their values. All values should be processed to be pure text string that can be understood by human. All features that contain unreadable information (e.g. image, video, audio, url, ID string ,etc.) should be converted (when possible) or removed (when not possible) to be pure text string.\"\n",
    "}\n",
    "```\n",
    "This JSON is stored as `<DATASET_NAME>_interaction.jsonl`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the raw data\n",
    "\n",
    "You can download the raw data from the following links:\n",
    "- [MobileRec](https://huggingface.co/datasets/recmeapp/mobilerec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Setting of the Filtered Dataset\n",
    "DATASET_NAME = \"mobilerec\"\n",
    "DATASET_PATH = \"<SOURCE_PATH>\"\n",
    "OUTPUT_PATH = \"<PROJECT_PATH>\"\n",
    "MIN_INTERACTION_CNT = 5     # The minimum number of interactions for a user to be included in the dataset.\n",
    "MAX_INTERACTION_CNT = 20  # The maximum number of interactions for a user to be included in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify the file structure of the dataset\n",
    "\n",
    "import os\n",
    "# List all files and subfolders in the dataset directory, excluding hidden ones\n",
    "print(\"Files and subfolders in dataset directory:\")\n",
    "for root, dirs, files in os.walk(DATASET_PATH):\n",
    "    # Remove hidden directories\n",
    "    dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "    \n",
    "    level = root.replace(DATASET_PATH, '').count(os.sep)\n",
    "    indent = ' ' * 4 * level\n",
    "    folder_name = os.path.basename(root)\n",
    "    if not folder_name.startswith('.'):\n",
    "        print(f\"{indent}{folder_name}/\")\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        # Only show non-hidden files\n",
    "        visible_files = [f for f in files if not f.startswith('.')]\n",
    "        for f in visible_files:\n",
    "            print(f\"{subindent}{f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Structure\n",
    "> Fill the file structure here so the LLM assistant can write the code to load the dataset.\n",
    "\n",
    "```txt\n",
    "Files and subfolders in dataset directory:\n",
    "mobilerec/\n",
    "    README.md\n",
    "    interactions/\n",
    "        mobilerec_final.csv\n",
    "    app_meta/\n",
    "        app_meta.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the dataset\n",
    "\n",
    "# Load the dataset based on the file structure and the README (if applicable).\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "mobilerec_df = pd.read_csv(os.path.join(DATASET_PATH, \"interactions\", \"mobilerec_final.csv\"), nrows=100000)\n",
    "\n",
    "print(f'Loaded {len(mobilerec_df)} interactions from MobileRec dataset')\n",
    "\n",
    "meta_df = pd.read_csv(os.path.join(DATASET_PATH, \"app_meta\", \"app_meta.csv\"))\n",
    "\n",
    "print(f'Loaded {len(meta_df)} items from MobileRec dataset')\n",
    "\n",
    "\n",
    "# Display column names and sample values for each dataframe\n",
    "print(\"\\nMobileRec Interactions DataFrame Columns:\")\n",
    "print(\"----------------------------------------\")\n",
    "for col in mobilerec_df.columns:\n",
    "    print(f\"{col}:\")\n",
    "    print(mobilerec_df[col].head())\n",
    "    print()\n",
    "\n",
    "print(\"\\nMeta DataFrame Columns:\") \n",
    "print(\"------------------------\")\n",
    "for col in meta_df.columns:\n",
    "    print(f\"{col}:\")\n",
    "    print(meta_df[col].head())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Convert the dataset to the unified format\n",
    "# Use tqdm and pandas.progress_apply to process the dataset.\n",
    "# Based on the data descriptions, convert the dataset to 3 dataframes: item_df, user_df, interaction_df.\n",
    "# Write 3 row processing functions: process_item_df, process_user_df, process_interaction_df.\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "def process_item_df(row):\n",
    "    return {\n",
    "        \"item_id\": row[\"app_package\"],\n",
    "        \"item_description\": {\n",
    "            \"app_name\": row[\"app_name\"],\n",
    "            \"developer_name\": row[\"developer_name\"] if row[\"developer_name\"] != \"None\" else \"Unknown\",\n",
    "            \"app_category\": row[\"app_category\"],\n",
    "            \"description\": row[\"description\"],\n",
    "            \"content_rating\": row[\"content_rating\"],\n",
    "            \"num_reviews\": row[\"num_reviews\"],\n",
    "            \"price\": row[\"price\"] if row[\"price\"] != \"Install\" else \"Free\",\n",
    "            \"avg_rating\": str(row[\"avg_rating\"]),\n",
    "        },\n",
    "        \"item_features\": {\n",
    "            \"num_reviews\": int(row[\"num_reviews\"].replace(\",\", \"\")),\n",
    "            \"avg_rating\": float(row[\"avg_rating\"]),\n",
    "        }\n",
    "    }\n",
    "\n",
    "def process_user_df(row):\n",
    "    return {\n",
    "        \"user_id\": row[\"uid\"],\n",
    "        \"user_description\": {\n",
    "\n",
    "        },\n",
    "        \"user_features\": {\n",
    "            \"avg_rating\": row[\"rating\"],\n",
    "        }\n",
    "    }\n",
    "\n",
    "def process_interaction_df(row):\n",
    "    return {\n",
    "        \"user_id\": row[\"uid\"],\n",
    "        \"item_id\": row[\"app_package\"],\n",
    "        \"timestamp\": row[\"unix_timestamp\"],\n",
    "        \"behavior_features\": {\n",
    "            \"rating\": row[\"rating\"],\n",
    "            \"review\": row[\"review\"],\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Apply the processing functions to the dataset\n",
    "item_df = meta_df.progress_apply(process_item_df, axis=1).to_list()\n",
    "\n",
    "\n",
    "user_features = mobilerec_df.groupby(\"uid\").agg({\n",
    "    \"rating\": \"mean\",\n",
    "}).reset_index()\n",
    "user_df = user_features.progress_apply(process_user_df, axis=1).to_list()\n",
    "\n",
    "\n",
    "interaction_df = mobilerec_df.progress_apply(process_interaction_df, axis=1).to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Save the dataset\n",
    "\n",
    "\n",
    "item_df = pd.DataFrame(item_df)\n",
    "user_df = pd.DataFrame(user_df)\n",
    "interaction_df = pd.DataFrame(interaction_df)\n",
    "\n",
    "\n",
    "print(f\"\\nFinal shapes:\")\n",
    "print(f\"Items: {len(item_df)}\")\n",
    "print(f\"Users: {len(user_df)}\")\n",
    "print(f\"Interactions: {len(interaction_df)}\")\n",
    "\n",
    "# Save the processed data\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "print(\"\\nSaving files...\")\n",
    "\n",
    "interaction_df.to_json(os.path.join(OUTPUT_PATH, f\"{DATASET_NAME}_interaction.jsonl\"), lines=True, orient=\"records\")\n",
    "user_df.to_json(os.path.join(OUTPUT_PATH, f\"{DATASET_NAME}_user_feature.jsonl\"), lines=True, orient=\"records\")\n",
    "item_df.to_json(os.path.join(OUTPUT_PATH, f\"{DATASET_NAME}_item_feature.jsonl\"), lines=True, orient=\"records\")\n",
    "\n",
    "print(\"\\nProcessing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
