{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Construction - Movielens-1M\n",
    "\n",
    "This notebook aims to model any recommender system datasets to the unified sequential format of pure text string, serving as the input of the user simulator LLM.\n",
    "\n",
    "A recommender system data usually consists of 3 critical components: user, item and behavior. The user and item are usually represented by their IDs, while the behavior is usually represented by their interactions.\n",
    "\n",
    "The goal of this notebook is to transform the original data into a unified format, with two types of JSON format:\n",
    "\n",
    "- Item Feature JSON: This JSON contains a list of all items in the dataset, each element is following the format:\n",
    "```json\n",
    "{\n",
    "    \"item_id\": \"item_id (str), a unique identifier for the item\",\n",
    "    \"item_description\": \"item_description (dict[str, str]), a dictionary of item attributes and their values. All values should be processed to be pure text string that can be understood by human. All features that contain unreadable information (e.g. image, video, audio, url, ID string ,etc.) should be converted (when possible) or removed (when not possible) to be pure text string.\",\n",
    "    \"item_features\": \"item_features (dict[str, Any]), a dictionary of item features (except for those in item_description) and their values. \"\n",
    "This JSON is stored as `<DATASET_NAME>_item_feature.jsonl`.\n",
    "\n",
    "- User Feature JSON: This JSON contains a list of all items in the dataset, each element is following the format:\n",
    "```json\n",
    "{\n",
    "    \"user_id\": \"user_id (str), a unique identifier for the user\",\n",
    "    \"user_description\": \"user_description (dict[str, str]), a dictionary of user attributes and their values. All values should be processed to be pure text string that can be understood by human. All features that contain unreadable information (e.g. image, video, audio, url, ID string ,etc.) should be converted (when possible) or removed (when not possible) to be pure text string.\",\n",
    "    \"user_features\": \"user_features (dict[str, Any]), a dictionary of user features (except for those in user_description) and their values. \"\n",
    "}\n",
    "```\n",
    "This JSON is stored as `<DATASET_NAME>_user_feature.jsonl`.\n",
    "\n",
    "- Interaction JSON: This JSON contains a list of all user behaviors in the dataset, each element is following the format:\n",
    "```json\n",
    "{\n",
    "    \"user_id\": \"user_id (str), a unique identifier for the user\",\n",
    "    \"item_id\": \"item_id (str), the ID of the item that the user has interacted with\",\n",
    "    \"timestamp\": \"timestamp (str), the timestamp of the interaction in the format of YYYY-MM-DD HH:MM:SS. When the timestamp is not available, it should be set to the random timestamp.\",\n",
    "    \"behavior_features\": \"behavior_features (dict[str, Any]), a dictionary of behavior features and their values. All values should be processed to be pure text string that can be understood by human. All features that contain unreadable information (e.g. image, video, audio, url, ID string ,etc.) should be converted (when possible) or removed (when not possible) to be pure text string.\"\n",
    "}\n",
    "```\n",
    "This JSON is stored as `<DATASET_NAME>_interaction.jsonl`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the raw data\n",
    "\n",
    "You can download the raw data from the following links:\n",
    "- [Movielens-1M](https://files.grouplens.org/datasets/movielens/ml-1m.zip)\n",
    "\n",
    "After downloading the raw data, you can unzip the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Setting of the Filtered Dataset\n",
    "DATASET_NAME = \"ml-1m\"\n",
    "DATASET_PATH = \"<SOURCE_PATH>\"\n",
    "OUTPUT_PATH = \"<PROJECT_PATH>/raws/\"\n",
    "MIN_INTERACTION_CNT = 5     # The minimum number of interactions for a user to be included in the dataset.\n",
    "MAX_INTERACTION_CNT = 20  # The maximum number of interactions for a user to be included in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify the file structure of the dataset\n",
    "\n",
    "import os\n",
    "# List all files in the dataset directory\n",
    "print(\"Files in dataset directory:\")\n",
    "for file in os.listdir(DATASET_PATH):\n",
    "    print(f\"- {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1: Load README\n",
    "\n",
    "# README_FILE_NAME = \"README\"\n",
    "# README_FILE_PATH = os.path.join(DATASET_PATH, README_FILE_NAME)\n",
    "\n",
    "# with open(README_FILE_PATH, \"r\") as file:\n",
    "#     README_CONTENT = file.read()\n",
    "\n",
    "# print(README_CONTENT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the ratings data\n",
    "ratings_df = pd.read_csv(os.path.join(DATASET_PATH, \"ratings.dat\"), \n",
    "                        sep=\"::\", \n",
    "                        header=None, \n",
    "                        names=['UserID', 'MovieID', 'Rating', 'Timestamp'],\n",
    "                        engine='python')\n",
    "\n",
    "# Load the users data\n",
    "users_df = pd.read_csv(os.path.join(DATASET_PATH, \"users.dat\"),\n",
    "                      sep=\"::\",\n",
    "                      header=None,\n",
    "                      names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'],\n",
    "                      engine='python')\n",
    "\n",
    "# Load the movies data\n",
    "movies_df = pd.read_csv(os.path.join(DATASET_PATH, \"movies.dat\"),\n",
    "                       sep=\"::\",\n",
    "                       header=None,\n",
    "                       names=['MovieID', 'Title', 'Genres'],\n",
    "                       encoding='latin-1',\n",
    "                       engine='python')\n",
    "\n",
    "# Display the first few rows of each dataframe\n",
    "print(\"Ratings DataFrame:\")\n",
    "print(ratings_df.head())\n",
    "print(\"\\nUsers DataFrame:\")\n",
    "print(users_df.head())\n",
    "print(\"\\nMovies DataFrame:\")\n",
    "print(movies_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Convert each item as a full-text description.\n",
    "\n",
    "ITEM_DESCRIPTION_TEMPLATE = \"'{title}' [{genres}]\"\n",
    "\n",
    "def create_movie_description(row):\n",
    "    # Extract year from title if present\n",
    "    title = row['Title']\n",
    "    \n",
    "    # Convert genres from '|' separated string to list\n",
    "    genres = row['Genres']\n",
    "\n",
    "    # Create description using a single format string\n",
    "    description = ITEM_DESCRIPTION_TEMPLATE.format(title=title, genres=genres)\n",
    "    \n",
    "    return description\n",
    "\n",
    "# Create text descriptions for movies\n",
    "movies_df['Description'] = movies_df.apply(create_movie_description, axis=1)\n",
    "\n",
    "print(\"Example movie descriptions:\")\n",
    "print(movies_df[['MovieID', 'Description']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step Extra: Map user feature ids to text descriptions, based on README\n",
    "\n",
    "Gender_map = {\n",
    "    \"F\": \"female\",\n",
    "    \"M\": \"male\"\n",
    "}\n",
    "\n",
    "Age_map = {\n",
    "    1: \"Under 18\",\n",
    "    18: \"18-24\",\n",
    "    25: \"25-34\",\n",
    "    35: \"35-44\",\n",
    "    45: \"45+\"\n",
    "}\n",
    "\n",
    "Occupation_map = {\n",
    "    0: \"other\",\n",
    "    1: \"academic/educator\", \n",
    "    2: \"artist\",\n",
    "    3: \"clerical/admin\",\n",
    "    4: \"college/grad student\",\n",
    "    5: \"customer service\",\n",
    "    6: \"doctor/health care\",\n",
    "    7: \"executive/managerial\",\n",
    "    8: \"farmer\",\n",
    "    9: \"homemaker\",\n",
    "    10: \"K-12 student\",\n",
    "    11: \"lawyer\",\n",
    "    12: \"programmer\",\n",
    "    13: \"retired\",\n",
    "    14: \"sales/marketing\",\n",
    "    15: \"scientist\",\n",
    "    16: \"self-employed\",\n",
    "    17: \"technician/engineer\",\n",
    "    18: \"tradesman/craftsman\",\n",
    "    19: \"unemployed\",\n",
    "    20: \"writer\"\n",
    "}\n",
    "\n",
    "# Map Zip codes to locations using uszipcode package\n",
    "# import sqlalchemy_mate\n",
    "# import sys\n",
    "# from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "# class ExtendedBase:\n",
    "#     __abstract__ = True\n",
    "\n",
    "# if not hasattr(sqlalchemy_mate, 'ExtendedBase'):\n",
    "#     sqlalchemy_mate.ExtendedBase = ExtendedBase\n",
    "    \n",
    "from uszipcode import SearchEngine\n",
    "\n",
    "def get_zipcode_info(zipcode):\n",
    "    try:\n",
    "        search = SearchEngine()\n",
    "        result = search.by_zipcode(str(zipcode))\n",
    "        if result:\n",
    "           return result.city + \", \" + result.state\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "Zipcode_map = {}\n",
    "unique_zipcodes = users_df['Zip-code'].unique()\n",
    "\n",
    "for zipcode in unique_zipcodes:\n",
    "    if pd.notna(zipcode):  # Skip NaN values\n",
    "        info = get_zipcode_info(zipcode)\n",
    "        if info:\n",
    "            Zipcode_map[zipcode] = info\n",
    "\n",
    "users_df['Zip-code'] = users_df['Zip-code'].apply(lambda x: Zipcode_map.get(x, \"Unknown\"))\n",
    "users_df['Gender'] = users_df['Gender'].apply(lambda x: Gender_map.get(x, \"Unknown\"))\n",
    "users_df['Age'] = users_df['Age'].apply(lambda x: Age_map.get(x, \"Unknown\"))\n",
    "users_df['Occupation'] = users_df['Occupation'].apply(lambda x: Occupation_map.get(x, \"Unknown\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROFILE_TEMPLATE = \"\"\"Gender: {gender}, Age: {age}, Occupation: {occupation}, Location: {zipcode}\n",
    "\"\"\"\n",
    "\n",
    "users_df['Profile'] = users_df.apply(lambda row: USER_PROFILE_TEMPLATE.format(user_id=row['UserID'], gender=row['Gender'], age=row['Age'], occupation=row['Occupation'], zipcode=row['Zip-code']), axis=1)\n",
    "\n",
    "users_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = users_df\n",
    "user_df = users_df.rename(columns={'UserID': 'user_id', 'Gender': 'gender', 'Age': 'age', 'Occupation': 'occupation', 'Zip-code': 'zipcode'})\n",
    "item_df = movies_df\n",
    "item_df = item_df.rename(columns={'MovieID': 'item_id', 'Title': 'title', 'Genres': 'genres'})\n",
    "interactions_df = ratings_df\n",
    "interactions_df = interactions_df.rename(columns={'UserID': 'user_id', 'MovieID': 'item_id', 'Rating': 'rating', 'Timestamp': 'timestamp'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset with the minimum and maximum number of interactions\n",
    "MIN_INTERACTION_CNT = 5\n",
    "MAX_INTERACTION_CNT = 20\n",
    "\n",
    "user_count = interactions_df.groupby('user_id').size()\n",
    "user_count = user_count[user_count >= MIN_INTERACTION_CNT]\n",
    "\n",
    "interactions_df = interactions_df[interactions_df['user_id'].isin(user_count.index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Convert the dataset to the unified format\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def extract_year_from_title(title):\n",
    "    \"\"\"Extract year from title if present\"\"\"\n",
    "    # Regular expression to find year in parentheses\n",
    "    year_match = re.search(r'\\((\\d{4})\\)', title)\n",
    "    if year_match:\n",
    "        return year_match.group(1)\n",
    "    return None\n",
    "\n",
    "def parse_date(date_str):\n",
    "    \"\"\"Convert various date formats to YYYY-MM-DD HH:MM:SS format\"\"\"\n",
    "    if isinstance(date_str, (int, np.int64)):\n",
    "        # If input is timestamp (integer), convert it to datetime\n",
    "        try:\n",
    "            dt = datetime.fromtimestamp(date_str)\n",
    "            return dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        except:\n",
    "            return None\n",
    "            \n",
    "    if not date_str or (isinstance(date_str, str) and date_str.strip() == ''):\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        # 尝试解析Goodreads格式的日期\n",
    "        dt = datetime.strptime(date_str, '%a %b %d %H:%M:%S %z %Y')\n",
    "        return dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_movie(movie):\n",
    "    \n",
    "    item_description = {\n",
    "        \"title\": movie['title'],\n",
    "        \"genres\": movie['genres'],\n",
    "        \"year\": extract_year_from_title(movie['title'])\n",
    "    }\n",
    "    \n",
    "    item_features = {\n",
    "        \"year\": extract_year_from_title(movie['title'])\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        \"item_id\": str(movie['item_id']),\n",
    "        \"item_description\": item_description,\n",
    "        \"item_features\": item_features\n",
    "    }\n",
    "\n",
    "def process_user(user):\n",
    "    user_description = {\n",
    "        \"gender\": user['gender'],\n",
    "        \"age\": user['age'],\n",
    "        \"occupation\": user['occupation'],\n",
    "        \"location\": user['zipcode']\n",
    "    }\n",
    "    \n",
    "    user_features = {\n",
    "    }\n",
    "    return {\n",
    "        \"user_id\": str(user['user_id']),\n",
    "        \"user_description\": user_description,\n",
    "        \"user_features\": user_features\n",
    "    }\n",
    "\n",
    "def process_interaction(interaction):\n",
    "    behavior_features = {\n",
    "        \"rating\": float(interaction['rating']) if pd.notna(interaction['rating']) else \"Not Rated\"\n",
    "    }\n",
    "    \n",
    "    timestamp = parse_date(interaction['timestamp'])\n",
    "    if not timestamp:\n",
    "        return None\n",
    "        \n",
    "    return {\n",
    "        \"user_id\": str(interaction['user_id']),\n",
    "        \"item_id\": str(interaction['item_id']),\n",
    "        \"timestamp\": timestamp,\n",
    "        \"behavior_features\": behavior_features\n",
    "    }\n",
    "\n",
    "# Process items (books)\n",
    "tqdm.pandas(desc=\"Processing books\")\n",
    "item_records = item_df.progress_apply(process_movie, axis=1).tolist()\n",
    "\n",
    "# Process users \n",
    "tqdm.pandas(desc=\"Processing users\")\n",
    "user_records = user_df.progress_apply(process_user, axis=1).tolist()\n",
    "\n",
    "# Process interactions\n",
    "tqdm.pandas(desc=\"Processing interactions\")\n",
    "interaction_records = interactions_df.progress_apply(process_interaction, axis=1).dropna().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Save the dataset\n",
    "import os\n",
    "# Convert records to pandas DataFrames\n",
    "interaction_df = pd.DataFrame.from_records(interaction_records)\n",
    "user_df = pd.DataFrame.from_records(user_records) \n",
    "item_df = pd.DataFrame.from_records(item_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "interaction_df.to_json(os.path.join(OUTPUT_PATH, f\"{DATASET_NAME}_interaction.jsonl\"), lines=True, orient=\"records\")\n",
    "user_df.to_json(os.path.join(OUTPUT_PATH, f\"{DATASET_NAME}_user_feature.jsonl\"), lines=True, orient=\"records\")\n",
    "item_df.to_json(os.path.join(OUTPUT_PATH, f\"{DATASET_NAME}_item_feature.jsonl\"), lines=True, orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
