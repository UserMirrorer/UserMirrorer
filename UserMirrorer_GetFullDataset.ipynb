{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Obatining the Full Dataset of UserMirrorer\n",
        "\n",
        "In our `UserMirrorer` dataset, the raw data from `MIND` and `MovieLens-1M` datasets are distributed under restrictive licenses and cannot\n",
        "be included directly.\n",
        "\n",
        "Therefore, this notebook provides a comprehensive, step-by-step pipeline to load the original archives, execute all necessary preprocessing\n",
        "operations, and assemble the final UserMirrorer training, and test splits.\n",
        "\n",
        "To derive the full dataset, just click \"run all\" to execute all cells."
      ],
      "metadata": {
        "id": "mNudlXDmoYwz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eBgVHdSoTvV"
      },
      "source": [
        "------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/UserMirrorer/UserMirrorer"
      ],
      "metadata": {
        "id": "wU6WetgQojVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd UserMirrorer\n",
        "!pip install -U datasets tqdm uszipcode sqlalchemy-mate==2.0.0.0"
      ],
      "metadata": {
        "id": "yptOj3sco3vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://recodatasets.z20.web.core.windows.net/newsrec/MINDlarge_train.zip\n",
        "! wget https://recodatasets.z20.web.core.windows.net/newsrec/MINDlarge_dev.zip\n",
        "! wget https://recodatasets.z20.web.core.windows.net/newsrec/MINDlarge_test.zip\n",
        "! wget --no-check-certificate https://files.grouplens.org/datasets/movielens/ml-1m.zip"
      ],
      "metadata": {
        "id": "TbkRtnFVpX94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip MINDlarge_train.zip -d MINDlarge\n",
        "!unzip MINDlarge_dev.zip -d MINDlarge_dev\n",
        "!unzip MINDlarge_test.zip -d MINDlarge_test\n",
        "!mv MINDlarge_dev/behaviors.tsv MINDlarge/behaviors_valid.tsv\n",
        "!mv MINDlarge_dev/news.tsv MINDlarge/news_valid.tsv\n",
        "!mv MINDlarge_test/news.tsv MINDlarge/news_test.tsv\n",
        "!unzip ml-1m.zip"
      ],
      "metadata": {
        "id": "vbj7iSpO5tUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocessing/DataProcessor_ML-1M.py --source_path ml-1m --project_path UserM"
      ],
      "metadata": {
        "id": "GTbfeTIu6A_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocessing/DataProcessor_MIND.py --source_path MINDlarge --project_path UserM"
      ],
      "metadata": {
        "id": "GiFx3x0T6Z2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlWb5O0NoTvX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from usermirrorer.strategy.mind_strategy import MINDMappingStrategy, MINDDataStrategy\n",
        "from usermirrorer.strategy.ml1m_strategy import ML1MDataStrategy\n",
        "from usermirrorer.formatter.mapping import MappingStrategy\n",
        "from usermirrorer.formatter.formatter import DataFormatter\n",
        "from usermirrorer.generator.template import texts_to_messages, convert_action_list\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "random.seed(0)\n",
        "np.random.rand(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Full Training Set and Eval Set"
      ],
      "metadata": {
        "id": "Uoe-P8_VTvUj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3sjPZ_IoTvY"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"MirrorUser/UserMirrorer\", split=\"train\")\n",
        "train = dataset.to_pandas()\n",
        "\n",
        "dataset = load_dataset(\"MirrorUser/UserMirrorer-eval\", split=\"test\")\n",
        "test = dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Movielens-1M"
      ],
      "metadata": {
        "id": "0EvQd1hlT0gv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01txl2F4oTvY"
      },
      "outputs": [],
      "source": [
        "data_formatter = DataFormatter(\n",
        "    ds=ML1MDataStrategy(\"UserM\", \"ml-1m\"),\n",
        "    mp=MappingStrategy()\n",
        ")\n",
        "\n",
        "train_split = train[train[\"dataset\"] == \"ml-1m\"].copy()\n",
        "train_split[\"user_id\"] = train_split[\"user_id\"].astype(int)\n",
        "train_split[\"item_id\"] = train_split[\"item_id\"].astype(int)\n",
        "train_split[\"impression_list\"] = train_split[\"impression_list\"].apply(lambda x: [int(i) for i in x])\n",
        "\n",
        "train_result = data_formatter.get_all_details(train_split)\n",
        "train_result[\"prompt\"] = train_result[\"text\"].apply(lambda x: texts_to_messages(convert_action_list(x)))\n",
        "\n",
        "train.loc[train_result.index, \"prompt\"] = train_result[\"prompt\"]\n",
        "train.loc[train_result.index, \"messages_chosen\"] = train.loc[train_result.index].apply(lambda x: x[\"prompt\"] + [x[\"messages_chosen\"][-1]], axis=1)\n",
        "train.loc[train_result.index, \"messages_rejected\"] = train.loc[train_result.index].apply(lambda x: x[\"prompt\"] + [x[\"messages_rejected\"][-1]], axis=1)\n",
        "\n",
        "test_split = test[test[\"dataset\"] == \"ml-1m\"].copy()\n",
        "test_split[\"user_id\"] = test_split[\"user_id\"].astype(int)\n",
        "test_split[\"item_id\"] = test_split[\"item_id\"].astype(int)\n",
        "test_split[\"impression_list\"] = test_split[\"impression_list\"].apply(lambda x: [int(i) for i in x])\n",
        "\n",
        "test_result = data_formatter.get_all_details(test_split)\n",
        "test.loc[test_result.index, \"text\"] = test_result[\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MIND"
      ],
      "metadata": {
        "id": "siPvleAmT27s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZipDk3WoTvY"
      },
      "outputs": [],
      "source": [
        "data_formatter = DataFormatter(\n",
        "    ds=MINDDataStrategy(\"UserM\", \"MIND\"),\n",
        "    mp=MINDMappingStrategy()\n",
        ")\n",
        "\n",
        "train_split = train[train[\"dataset\"] == \"MIND\"].copy()\n",
        "\n",
        "train_result = data_formatter.get_all_details(train_split)\n",
        "train_result[\"prompt\"] = train_result[\"text\"].apply(lambda x: texts_to_messages(convert_action_list(x)))\n",
        "\n",
        "train.loc[train_result.index, \"prompt\"] = train_result[\"prompt\"]\n",
        "train.loc[train_result.index, \"messages_chosen\"] = train.loc[train_result.index].apply(lambda x: x[\"prompt\"] + [x[\"messages_chosen\"][-1]], axis=1)\n",
        "train.loc[train_result.index, \"messages_rejected\"] = train.loc[train_result.index].apply(lambda x: x[\"prompt\"] + [x[\"messages_rejected\"][-1]], axis=1)\n",
        "\n",
        "test_split = test[test[\"dataset\"] == \"MIND\"].copy()\n",
        "\n",
        "test_result = data_formatter.get_all_details(test_split)\n",
        "test.loc[test_result.index, \"text\"] = test_result[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNCRHYY1oTvY"
      },
      "outputs": [],
      "source": [
        "train = train.loc[:, [\"dataset\", \"messages_chosen\", \"messages_rejected\"]]\n",
        "train.to_json(\"UserMirrorer-Full.jsonl\", orient=\"records\", lines=True)\n",
        "train.to_json(\"UserMirrorer-Full.jsonl.gz\", orient=\"records\", lines=True, compression=\"gzip\")\n",
        "\n",
        "test = test.drop(columns=[\"impression_list\"])\n",
        "test.to_json(\"UserMirrorer-eval-Full.jsonl\", orient=\"records\", lines=True)\n",
        "test.to_json(\"UserMirrorer-eval-Full.jsonl.gz\", orient=\"records\", lines=True, compression=\"gzip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sha1sum UserMirrorer-eval-Full.jsonl\n",
        "!sha1sum UserMirrorer-Full.jsonl"
      ],
      "metadata": {
        "id": "UhMGCb-mxv2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SHA256 of the derived dataset file should be:\n",
        "\n",
        "- `UserMirrorer-Full.jsonl`: `c3b819d7acab4d9b10dbafc411b18f49c5d17798`\n",
        "\n",
        "- `UserMirrorer-eval-Full.jsonl`: `61e40dd5cb4649b6fd19c02afa7b13e4ec5ff276`"
      ],
      "metadata": {
        "id": "rkQj8DZ98Alg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"UserMirrorer-Full.jsonl.gz\")"
      ],
      "metadata": {
        "id": "GXgya3DlS5AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"UserMirrorer-eval-Full.jsonl.gz\")"
      ],
      "metadata": {
        "id": "i_Hol1SZx0yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset file `UserMirrorer-Full.jsonl.gz` and `UserMirrorer-eval-Full.jsonl.gz` will be downloaded automatically. Or you can doanload it manually in *files*."
      ],
      "metadata": {
        "id": "n36tkKdXT_QB"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "alpaca",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}