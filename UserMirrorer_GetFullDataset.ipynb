{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Obatining the Full Dataset of UserMirrorer\n",
        "\n",
        "In our `UserMirrorer` dataset, the raw data from `MIND` and `MovieLens-1M` datasets are distributed under restrictive licenses and cannot\n",
        "be included directly.\n",
        "\n",
        "Therefore, this notebook provides a comprehensive, step-by-step pipeline to load the original archives, execute all necessary preprocessing\n",
        "operations, and assemble the final UserMirrorer training, validation, and test splits.\n",
        "\n",
        "To derive the full dataset, just click \"run all\" to execute all cells."
      ],
      "metadata": {
        "id": "mNudlXDmoYwz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eBgVHdSoTvV"
      },
      "source": [
        "------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/UserMirrorer/UserMirrorer"
      ],
      "metadata": {
        "id": "wU6WetgQojVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd UserMirrorer\n",
        "!pip install -U datasets tqdm uszipcode sqlalchemy-mate==2.0.0.0"
      ],
      "metadata": {
        "id": "yptOj3sco3vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://recodatasets.z20.web.core.windows.net/newsrec/MINDlarge_train.zip\n",
        "! wget https://recodatasets.z20.web.core.windows.net/newsrec/MINDlarge_dev.zip\n",
        "! wget https://recodatasets.z20.web.core.windows.net/newsrec/MINDlarge_test.zip\n",
        "! wget --no-check-certificate https://files.grouplens.org/datasets/movielens/ml-1m.zip"
      ],
      "metadata": {
        "id": "TbkRtnFVpX94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip MINDlarge_train.zip -d MINDlarge\n",
        "!unzip MINDlarge_dev.zip -d MINDlarge_dev\n",
        "!unzip MINDlarge_test.zip -d MINDlarge_test\n",
        "!mv MINDlarge_dev/behaviors.tsv MINDlarge/behaviors_valid.tsv\n",
        "!mv MINDlarge_dev/news.tsv MINDlarge/news_valid.tsv\n",
        "!mv MINDlarge_test/news.tsv MINDlarge/news_test.tsv\n",
        "!unzip ml-1m.zip"
      ],
      "metadata": {
        "id": "vbj7iSpO5tUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocessing/DataProcessor_ML-1M.py --source_path ml-1m --project_path UserM"
      ],
      "metadata": {
        "id": "GTbfeTIu6A_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocessing/DataProcessor_MIND.py --source_path MINDlarge --project_path UserM"
      ],
      "metadata": {
        "id": "GiFx3x0T6Z2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlWb5O0NoTvX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from usermirrorer.strategy.mind_strategy import MINDMappingStrategy, MINDDataStrategy\n",
        "from usermirrorer.strategy.ml1m_strategy import ML1MDataStrategy\n",
        "from usermirrorer.formatter.mapping import MappingStrategy\n",
        "from usermirrorer.formatter.formatter import DataFormatter\n",
        "from usermirrorer.generator.template import texts_to_messages, convert_action_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Full Training Set and Eval Set"
      ],
      "metadata": {
        "id": "Uoe-P8_VTvUj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3sjPZ_IoTvY"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"MirrorUser/UserMirrorer\", split=\"train\")\n",
        "train = dataset.to_pandas()\n",
        "\n",
        "dataset = load_dataset(\"MirrorUser/UserMirrorer-eval\", split=\"test\")\n",
        "test = dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Movielens-1M"
      ],
      "metadata": {
        "id": "0EvQd1hlT0gv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01txl2F4oTvY"
      },
      "outputs": [],
      "source": [
        "data_formatter = DataFormatter(\n",
        "    ds=ML1MDataStrategy(\"UserM\", \"ml-1m\"),\n",
        "    mp=MappingStrategy()\n",
        ")\n",
        "\n",
        "train_split = train[train[\"dataset\"] == \"ml-1m\"].copy()\n",
        "train_split[\"user_id\"] = train_split[\"user_id\"].astype(int)\n",
        "train_split[\"item_id\"] = train_split[\"item_id\"].astype(int)\n",
        "train_split[\"impression_list\"] = train_split[\"impression_list\"].apply(lambda x: [int(i) for i in x])\n",
        "\n",
        "train_result = data_formatter.get_all_details(train_split)\n",
        "train_result[\"prompt\"] = train_result[\"text\"].apply(lambda x: texts_to_messages(convert_action_list(x)))\n",
        "\n",
        "train.loc[train_result.index, \"prompt\"] = train_result[\"prompt\"]\n",
        "train.loc[train_result.index, \"messages_chosen\"] = train.loc[train_result.index].apply(lambda x: x[\"prompt\"] + [x[\"messages_chosen\"][-1]], axis=1)\n",
        "train.loc[train_result.index, \"messages_rejected\"] = train.loc[train_result.index].apply(lambda x: x[\"prompt\"] + [x[\"messages_rejected\"][-1]], axis=1)\n",
        "\n",
        "test_split = test[test[\"dataset\"] == \"ml-1m\"].copy()\n",
        "test_split[\"user_id\"] = test_split[\"user_id\"].astype(int)\n",
        "test_split[\"item_id\"] = test_split[\"item_id\"].astype(int)\n",
        "test_split[\"impression_list\"] = test_split[\"impression_list\"].apply(lambda x: [int(i) for i in x])\n",
        "\n",
        "test_result = data_formatter.get_all_details(test_split)\n",
        "test.loc[test_result.index, \"text\"] = test_result[\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MIND"
      ],
      "metadata": {
        "id": "siPvleAmT27s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZipDk3WoTvY"
      },
      "outputs": [],
      "source": [
        "data_formatter = DataFormatter(\n",
        "    ds=MINDDataStrategy(\"UserM\", \"MIND\"),\n",
        "    mp=MINDMappingStrategy()\n",
        ")\n",
        "\n",
        "train_split = train[train[\"dataset\"] == \"MIND\"].copy()\n",
        "\n",
        "train_result = data_formatter.get_all_details(train_split)\n",
        "train_result[\"prompt\"] = train_result[\"text\"].apply(lambda x: texts_to_messages(convert_action_list(x)))\n",
        "\n",
        "train.loc[train_result.index, \"prompt\"] = train_result[\"prompt\"]\n",
        "train.loc[train_result.index, \"messages_chosen\"] = train.loc[train_result.index].apply(lambda x: x[\"prompt\"] + [x[\"messages_chosen\"][-1]], axis=1)\n",
        "train.loc[train_result.index, \"messages_rejected\"] = train.loc[train_result.index].apply(lambda x: x[\"prompt\"] + [x[\"messages_rejected\"][-1]], axis=1)\n",
        "\n",
        "test_split = test[test[\"dataset\"] == \"MIND\"].copy()\n",
        "\n",
        "test_result = data_formatter.get_all_details(test_split)\n",
        "test.loc[test_result.index, \"text\"] = test_result[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNCRHYY1oTvY"
      },
      "outputs": [],
      "source": [
        "train = train.loc[:, [\"dataset\", \"messages_chosen\", \"messages_rejected\"]]\n",
        "train.to_json(\"UserMirrorer-Full.jsonl.gz\", orient=\"records\", lines=True, compression=\"gzip\")\n",
        "\n",
        "test = test.drop(columns=[\"impression_list\"])\n",
        "test.to_json(\"UserMirrorer-eval-Full.jsonl.gz\", orient=\"records\", lines=True, compression=\"gzip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"UserMirrorer-Full.jsonl.gz\")\n",
        "files.download(\"UserMirrorer-eval-Full.jsonl.gz\")"
      ],
      "metadata": {
        "id": "GXgya3DlS5AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset file `UserMirrorer-Full.jsonl.gz` and `UserMirrorer-eval-Full.jsonl.gz` will be downloaded automatically. Or you can doanload it manually in *files*."
      ],
      "metadata": {
        "id": "n36tkKdXT_QB"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "alpaca",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}