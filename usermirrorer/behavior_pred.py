
"""
Behavior Prediction Module

This module provides functionality for predicting user behavior based on a decision list
generated by an LLM. It includes functions for extracting decision strings from LLM responses,
and for predicting behavior using an LLM-based classifier.

The workflow:
1. Load the training data and convert action lists to LLM messages
2. Load the decision data, normalize JSON to extract choices, and align indices
3. Initialize the LLM-based classifier for decision prediction
4. Predict choices for each unique number of options
5. Write predictions to output file
"""
import os
import sys
import argparse
import pandas as pd
from tqdm import tqdm
import pandas as pd

sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(__file__)), ".."))

from usermirrorer.generator.classifier import LLMClassifier
from usermirrorer.generator.template import texts_to_messages, convert_action_list

def pred_with_decision_list(df: pd.DataFrame, model: LLMClassifier, choice_cnt: int) -> pd.DataFrame:
    """
    Generate predictions for each row in the DataFrame filtered by the given choice count.

    Parameters:
        df (pd.DataFrame): DataFrame with 'messages' and 'decision_list'.
        model (LLMClassifier): Classifier used to generate choice predictions.
        choice_cnt (int): Number of choice options per example.

    Returns:
        pd.DataFrame: The DataFrame with an added 'choice' column of predictions.
    """
    df_slice = df[df["choice_cnt"] == choice_cnt]
    data = df_slice.explode('decision_list').dropna(subset=['decision_list']).copy()
    message_with_decision = data.apply(lambda x: x['messages'] + [{"role": "assistant", "content": x['decision_list'].strip() + "\nBehavior: ["}], axis=1)
    output = model.run(
        messages=message_with_decision.tolist(),
        choices=[f"{chr(65 + i)}" for i in range(choice_cnt)],
    )
    data.loc[:, "choice"] = output
    grouped = data.groupby(level=0).agg(list)
    df.loc[grouped.index, "choice"] = grouped["choice"]
    return df

def get_decision_list(text: str) -> list:
    """
    Extract decision strings from the LLM response messages.

    Parameters:
        text (list): A list of message dicts with LLM response content.

    Returns:
        list: Extracted decision strings, or an empty list if parsing fails.
    """
    decision_list = []
    try:
        for e in text:
            decision_list.append(e['message']['content'].split("Behavior:")[0].strip())
    except:
        return []
    return decision_list

if __name__ == "__main__":  
    # Parse command-line arguments for model path, dataset, project path, GPU device, and version
    args = argparse.ArgumentParser()
    args.add_argument("--model_path", type=str, default="meta-llama/Llama-3.2-3B-Instruct")
    args.add_argument("--dataset", type=str, default="MIND")
    args.add_argument("--project_path", type=str)
    args.add_argument("--gpu_device", type=str, default="0", help="use comma-separated gpu ids for tensor parallelism")
    args.add_argument("--version", type=str, default="the version of the decision-making process, e.g. 'strong' or 'weak'")
    args = args.parse_args()

    # Construct file paths for input dataset, decisions, and output
    input = os.path.join(args.project_path, "datasets", f"{args.dataset}_train.jsonl")
    decisions = os.path.join(args.project_path, "decisions", f"{args.dataset}_decisions_{args.version}.jsonl")
    output = os.path.join(args.project_path, "probs", f"{args.dataset}_probs_{args.version}.jsonl")

    # Ensure the output directory exists
    if not os.path.exists(os.path.join(args.project_path, "probs")):
        os.makedirs(os.path.join(args.project_path, "probs"))

    # Load training data and convert action lists to LLM messages
    df = pd.read_json(input, lines=True)
    df['messages'] = df['text'].apply(lambda x: texts_to_messages(convert_action_list(x)))

    # Load decision data, normalize JSON to extract choices, and align indices
    decisions = pd.read_json(decisions, lines=True)
    decisions['custom_id'] = decisions['custom_id'].apply(lambda x: int(x.rsplit('-', 1)[-1]))
    decisions = decisions.set_index('custom_id')
    df['decision_list'] = pd.json_normalize(decisions['response']).set_index(decisions.index)['body.choices']
    df['decision_list'] = df['decision_list'].apply(get_decision_list)

    # Initialize the LLM-based classifier for decision prediction
    model = LLMClassifier(model_path=args.model_path, gpu_device=args.gpu_device)

    # Predict choices for each unique number of options
    df["choice"] = None
    for choice_cnt in tqdm(df["choice_cnt"].unique().tolist()):
        df = pred_with_decision_list(df, model, choice_cnt)

    # Write predictions to output file
    df.loc[:, ["user_id", "item_id", "decision_list", "choice"]].to_json(output, lines=True, orient="records", index=False)
    print(f"Output saved to {output}")
